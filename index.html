<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->

  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->

  <title>SLAC</title>
  <link rel="icon" type="image/x-icon" href="static/images/brain.ico">
  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      // Create an Intersection Observer for YouTube iframes
      const youtubeObserver = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          // Skip autoplay for iframes with no-autoplay class
          if (entry.target.classList.contains('no-autoplay')) return;
          
          if (entry.isIntersecting) {
            const iframe = entry.target;
            const currentSrc = iframe.src;
            if (!currentSrc.includes('autoplay=1')) {
              const baseUrl = currentSrc.split('?')[0];
              iframe.src = `${baseUrl}?autoplay=1&mute=1&playsinline=1&modestbranding=1`;
            }
          } else {
            const iframe = entry.target;
            const currentSrc = iframe.src;
            if (currentSrc.includes('autoplay=1')) {
              const baseUrl = currentSrc.split('?')[0];
              iframe.src = `${baseUrl}?mute=1&playsinline=1&modestbranding=1`;
            }
          }
        });
      }, {
        threshold: 0.5
      });

      // Create an Intersection Observer for local MP4 videos
      const videoObserver = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            entry.target.play().catch(function(error) {
              console.log("Video play failed:", error);
            });
          } else {
            entry.target.pause();
            // Reset video to start if it's not meant to loop
            if (entry.target.classList.contains('no-loop')) {
              entry.target.currentTime = 0;
            }
          }
        });
      }, {
        threshold: 0.5
      });

      // Observe all YouTube iframes (both in publication-video and card-video)
      document.querySelectorAll('.publication-video iframe, .card-video iframe').forEach(video => {
        youtubeObserver.observe(video);
      });

      // Observe all local MP4 videos
      document.querySelectorAll('video').forEach(video => {
        // Set video attributes
        video.muted = true;
        video.playsInline = true;
        // Only add loop if not explicitly marked as no-loop
        if (!video.classList.contains('no-loop')) {
          video.loop = true;
        }
        videoObserver.observe(video);
      });
    });
  </script>
</head>
<body>
  <section class="hero is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL</h2>
            <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://jiahenghu.github.io/" target="_blank">Jiaheng Hu</a>,</span>
                    <span class="author-block">
                      <a href="https://www.cs.utexas.edu/~pstone/" target="_blank">Peter Stone</a>,</span>
                    <span class="author-block">
                      <a href="https://robertomartinmartin.com/" target="_blank">Roberto Martín-Martín</a>
                    </span>
                    </div>
  
                    <div class="is-size-5 publication-authors">
                      <span class="author-block">The University of Texas at Austin
                        <!-- <br>Conferance name and year -->
                      </span>
                      <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                    </div>
  
                    <span class="is-size-5 publication-venue">CoRL 2025<span>
  
                    <div class="column has-text-centered">
                      <div class="publication-links">
                           <!-- Arxiv PDF link -->
                        <!-- <span class="link-block">
                          <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Paper</span>
                        </a>
                      </span> -->
  
                      <!-- Supplementary PDF link -->
                      <!-- <span class="link-block">
                        <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Supplementary</span>
                      </a>
                    </span> -->
  
                    <!-- ArXiv abstract Link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/abs/2506.04147" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
  
                    <!-- Github link -->
                    <span class="link-block">
                      <a href="https://github.com/JiahengHu/SLAC" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                    </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <br>
              <br>
              <p class="is-size-5">
                Learning tasks in the real world with reinforcement learning (RL) is very challenging, especially for complex robots such as bimanual mobile manipulators. 
                The high-dimensional, unconstrained action spaces worsen the already poor RL sample efficiency and raise significant safety concerns because naive exploration can easily damage the robot or its environment. 
                <br>
                <br>
                We address this problem with a powerful insight: both sample efficiency and safety can be dramatically improved by operating in the right action space, one that can be pre-learned entirely in simulation.   
              </p>
            </div>
          </div>
        </div>
        <br>
        <br>
        <br>
        <br>
        <br>
        <h2 class="title is-3" style="text-align: center;">Summary Video</h2>
        <div class="columns is-centered">
          <div class="column">
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/bj5GhjZbCXs" class="no-autoplay" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
          </div>
        </div>
        <br>
      </div>
    </div>
  </section>
  <!-- End youtube video -->

  <!-- <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-2" style="text-align: center;">Abstract</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
              Building capable household and industrial robots requires mastering the control of versatile,
              high-degree-of-freedom (DoF) systems such as mobile manipulators.
              While reinforcement learning (RL) holds promise for autonomously acquiring robot control policies,
              scaling it to high-DoF embodiments remains challenging.
              Direct RL in the real world demands both safe exploration and high sample efficiency,
              which are difficult to achieve in practice. Sim-to-real RL, on the other hand,
              is often brittle due to the reality gap. This paper introduces SLAC,
              a method that renders real-world RL feasible for complex embodiments by leveraging a
              low-fidelity simulator to pretrain a task-agnostic latent action space.
              SLAC trains this latent action space via a customized unsupervised skill discovery method designed to promote temporal abstraction,
              disentanglement, and safety, thereby facilitating efficient downstream learning. Once a latent action space is learned,
              SLAC uses it as the action interface for a novel off-policy RL algorithm to autonomously learn downstream tasks through real-world interactions.
              We evaluate SLAC against existing methods on a suite of bimanual mobile manipulation tasks, where it achieves state-of-the-art performance.
              Notably, SLAC learns contact-rich whole-body tasks in under an hour of real-world interactions,
              without relying on any demonstrations or hand-crafted behavior priors.
            </p>
          </div>
          <img src="static/images/pull.png" width="100%"/>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-2" style="text-align: center;">Two-Step SLAC Procedure</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
           
              We introduce SLAC, a framework that makes real-world RL feasible for high-DoF robots through a learned latent action space.
              SLAC consists of two steps: first, it leverages a low-fidelity simulator to pretrain a task-agnostic latent action space; then, it uses this space to drive real-world policy learning. 
            </p>
            <img src="static/images/pull.png" width="100%"/>
          </div>

          <h3 class="title is-4" style="text-align: left;">Step 1: Latent Action Space Learning in Simulation</h3>
          <div class="content has-text-justified">
            <p>
              How can we learn a good latent action space that allows us to efficiently handle different downstream tasks?
              Unsupervised Skill Discovery (USD) provides an elegant solution, through maximizing the empowerment of the latent action space.
              However, USD often requires a large number of samples to converge, which is not practical to run on a real robot.
              <br>
              <br>
              But we do not necessarily have to run USD on a real robot!
              Instead, SLAC leverages a low-fidelity simulator for USD.
              Even if there is a reality gap, the learned latent action space can still be used to drive real-world policy learning as long as it has enough coverage.
              Specifically, SLAC designs a novel USD objective that encourages temporally extended, disentangled, and safe latent actions, through the following pipeline:
            </p>
            <!-- <ul style="text-align: left;">
              <li>Learns temporally extended latent actions to reduce the exploration burden</li>
              <li>Enforces disentanglement between different latent dimensions to handle complex tasks</li>
              <li>Incorporates safety constraints to prevent dangerous behaviors</li>
            </ul> -->
            <!-- <p>
              These objectives are optimized through the following pipeline:
            </p> -->
          </div>
          <div class="publication-video" style="margin-top: -1rem; margin-bottom: 1rem;">
            <video
              src="static/videos/pipeline_1_low_res.mp4"
              style="width: 100%;aspect-ratio: 16/9;"
              class="no-loop"
              muted
              playsinline>
            </video>
          </div>

          <h3 class="title is-4" style="text-align: left;">Step 2: Real-World RL in the Learned Action Space</h3>
          <div class="content has-text-justified">
            <p>
              Once the latent action space is learned, SLAC trains a downstream policy in the learned action space.
              Specifically, we derive a novel off-policy RL algorithm on top of Soft Actor-Critic. Our algorithm not only handles discrete action space, 
              but can also leverage the dependencies between reward terms and latent action dimensions to decompose the RL training into parallel but easier sub-problems, thereby greatly reducing the sample complexity.
              We show the pipeline for downstream policy learning below:
            </p>
          </div>
          <div class="publication-video" style="margin-top: -1rem; margin-bottom: -1rem;">
            <video
              src="static/videos/website_videos2_low_res.mp4"
              style="width: 100%;aspect-ratio: 16/9;"
              class="no-loop"
              muted
              playsinline>
            </video>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">SLAC Real-World Training</h2>
          <p>
            In this video, we show one full training run for the board wiping task.
            The learned SLAC latent action space enables the robot to effectively explore the environment.
            Within 40 minutes of autonomous interactions, the robot learns
            to reliable wipe the whiteboard.
          </p>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/mmLUsGoK28Y" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="grid-container-one-no-box">
        <h2 class="title is-3 has-text-centered">Real-World Results</h2>
        <h2 class="title is-4">Policies Visualization</h2>
        <p>
          The SLAC framework does not require any demonstrations or hand-crafted behavior priors, and can be easily applied to a variety of tasks.
          We test SLAC on a suite of <strong>contact-rich, visuomotor</strong> bimanual mobile manipulation tasks, and show learned policies below.
        </p>
        <div class="grid-item">
          <div class="card-static-container">
            <div class="card-container">
              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/j7eYAJqAxaA"
                    width="100%"
                    height="280px"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Wipe a Whiteboard</strong></h3>
                  <p>SLAC policy continuously wipe a whiteboard by simultaneously moving its arms and base, while utilizing its active camera to keep track of the mark.</p>
                </div>
              </div>

              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/91dHyTkHH2g"
                    width="100%"
                    height="280px"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Wipe over Obstacle</strong></h3>
                  <p>SLAC policy learns to position its base such that it will not collide with the obstacle. In the meantime, it succecsfully wipes the mark on the whiteboard.</p>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="grid-item">
          <div class="card-static-container">
            <div class="card-container">
              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/azvZwjmmXTU"
                    width="100%"
                    height="280px"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Push to Tray</strong></h3>
                  <p>SLAC policy learns to use the broom in hand to push trash on the table into a tray.</p>
                </div>
              </div>

              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/18NYM-knLt8"
                    width="100%"
                    height="280px"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Sweep into Bag</strong></h3>
                  <p>SLAC learns to sweep trash off the table, while using a bag in the other hand to catch the trash.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

    </div>
  <!-- </section>

  <section class="section hero"> -->
    <div class="container is-max-desktop">
      <h2 class="title is-4" id="Simulation examples">Quantitative Results</h2>
      <div class="columns is-centered">
        <div class="column is-full-width is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
              Quantitatively, SLAC achieves significantly higher performance compared to state-of-the-art real-world RL and sim-to-real RL methods.
            </p>
          </div>
          <img src="static/images/success_plot.svg" width="70%"/>
          <div class="content has-text-justified">
            <p>
              More importantly, it stays safe during the entire training process, with minimal collisions nor excessive force!
            </p>
          </div>
          <img src="static/images/safety_plot.svg" width="70%"/>
        </div>
      </div>
    </div>
  <!-- </section>

  <section class="section hero"> -->
    <div class="container is-max-desktop">
      <div class="grid-container-one-no-box">
        <h2 class="title is-3">Learned Latent Actions Visualization</h2>
        <div class="content has-text-justified">
          <p>
            To better understand what SLAC learns during the simulation pretraining phase, we visualize the learned latent actions below.
            Each video shows the robot executing a sequence of different latent actions sampled from our learned latent action space.
            Notice how the actions are temporally extended, diverse, and safe - the robot never collides with itself or the environment.
            These properties are crucial for efficient downstream learning.
          </p>
        </div>
        <div class="columns is-centered">
          <div class="column is-three-fifths">
            <div style="display: flex; flex-direction: row; gap: 2rem; justify-content: center;">
              <div style="flex: 1;">
                <video
                  src="static/images/table.mp4"
                  style="width: 100%;aspect-ratio: 4/3;"
                  muted
                  playsinline
                  loop>
                </video>
              </div>
              <div style="flex: 1;">
                <video
                  src="static/images/board.mp4"
                  style="width: 100%;aspect-ratio: 4/3;"
                  muted
                  playsinline
                  loop>
                </video>
              </div>
            </div>
          </div>
        </div>

        <h2 class="title is-3">SLAC Beyond Robotics</h2>
        <div class="content has-text-justified">
          <p>
            While SLAC is primarily designed for robotics, its core principles can be applied to other domains with complex action spaces.
            Here we demonstrate SLAC's effectiveness on a centralized multi-agent particle domain, where a centralized controller needs to simulateously control 
            10 agents towards coordinated interactions with the landmarks. SLAC enables efficient downstream task learning on this challenging domain, outperforming previous state-of-the-art methods.
          </p>
        </div>
        <div class="columns is-centered">
          <div class="column is-two-fifths">
            <div class="card-mid">
              <div class="card-content">
                <div class="image-grid-part">
                  <img src="static/images/particle.gif" style="border: 2px solid black; width: 75%;">
                  <img src="static/images/particle.jpg" style="width: 100%;">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!--BibTex citation -->
  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @misc{hu2025slac,
          title={SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL}, 
          author={Jiaheng Hu and Peter Stone and Roberto Martín-Martín},
          year={2025},
          eprint={2506.04147},
          archivePrefix={arXiv},
          primaryClass={cs.RO},
          url={https://arxiv.org/abs/2506.04147}, 
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>

