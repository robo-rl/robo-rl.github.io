<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->

  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->

  <title>SLAC</title>
  <link rel="icon" type="image/x-icon" href="static/images/brain.ico">
  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      // Create an Intersection Observer for YouTube iframes
      const youtubeObserver = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          // Skip autoplay for iframes with no-autoplay class
          if (entry.target.classList.contains('no-autoplay')) return;
          
          if (entry.isIntersecting) {
            const iframe = entry.target;
            const currentSrc = iframe.src;
            if (!currentSrc.includes('autoplay=1')) {
              const baseUrl = currentSrc.split('?')[0];
              iframe.src = `${baseUrl}?autoplay=1&mute=1&playsinline=1&modestbranding=1`;
            }
          } else {
            const iframe = entry.target;
            const currentSrc = iframe.src;
            if (currentSrc.includes('autoplay=1')) {
              const baseUrl = currentSrc.split('?')[0];
              iframe.src = `${baseUrl}?mute=1&playsinline=1&modestbranding=1`;
            }
          }
        });
      }, {
        threshold: 0.5
      });

      // Create an Intersection Observer for local MP4 videos
      const videoObserver = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            entry.target.play().catch(function(error) {
              console.log("Video play failed:", error);
            });
          } else {
            entry.target.pause();
            // Reset video to start if it's not meant to loop
            if (entry.target.classList.contains('no-loop')) {
              entry.target.currentTime = 0;
            }
          }
        });
      }, {
        threshold: 0.5
      });

      // Observe all YouTube iframes (both in publication-video and card-video)
      document.querySelectorAll('.publication-video iframe, .card-video iframe').forEach(video => {
        youtubeObserver.observe(video);
      });

      // Observe all local MP4 videos
      document.querySelectorAll('video').forEach(video => {
        // Set video attributes
        video.muted = true;
        video.playsInline = true;
        // Only add loop if not explicitly marked as no-loop
        if (!video.classList.contains('no-loop')) {
          video.loop = true;
        }
        videoObserver.observe(video);
      });
    });
  </script>
</head>
<body>
  <section class="hero is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">SLAC: Simulation-Pretrained Latent Action Space for Real-World Policy Learning</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <!-- <span class="author-block">
                Anonymous Authors
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <!-- <h2 class="title is-3" style="text-align: center;">Video</h2> -->
        <div class="columns is-centered">
          <div class="column">
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/NBT7YlFzKUI" class="no-autoplay" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->

  <!-- <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-2" style="text-align: center;">Abstract</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
              Building capable household and industrial robots requires mastering the control of versatile,
              high-degree-of-freedom (DoF) systems such as mobile manipulators.
              While reinforcement learning (RL) holds promise for autonomously acquiring robot control policies,
              scaling it to high-DoF embodiments remains challenging.
              Direct RL in the real world demands both safe exploration and high sample efficiency,
              which are difficult to achieve in practice. Sim-to-real RL, on the other hand,
              is often brittle due to the reality gap. This paper introduces SLAC,
              a method that renders real-world RL feasible for complex embodiments by leveraging a
              low-fidelity simulator to pretrain a task-agnostic latent action space.
              SLAC trains this latent action space via a customized unsupervised skill discovery method designed to promote temporal abstraction,
              disentanglement, and safety, thereby facilitating efficient downstream learning. Once a latent action space is learned,
              SLAC uses it as the action interface for a novel off-policy RL algorithm to autonomously learn downstream tasks through real-world interactions.
              We evaluate SLAC against existing methods on a suite of bimanual mobile manipulation tasks, where it achieves state-of-the-art performance.
              Notably, SLAC learns contact-rich whole-body tasks in under an hour of real-world interactions,
              without relying on any demonstrations or hand-crafted behavior priors.
            </p>
          </div>
          <img src="static/images/pull.png" width="100%"/>
        </div>
      </div>
    </div>
  </section> -->

  <section class="section hero">
    <div class="container is-max-desktop">
      <h2 class="title is-2" style="text-align: center;">Overview</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
              Real-world reinforcement learning (RL) is extremely challenging for high degree-of-freedom robots like bimanual mobile manipulators, due to issues of sample inefficiency and safety. 
              Our key idea: both sample efficiency and safety can be greatly facillitated by a good action space!
              To this end, we introduce SLAC, a framework that makes real-world RL feasible for high-DoF robots through a learned latent action space.
              SLAC consists of two steps: first, it leverages a low-fidelity simulator to pretrain a task-agnostic latent action space; then, it uses this space to drive real-world policy learning. 
            </p>
            <img src="static/images/pull.png" width="100%"/>
          </div>

          <h3 class="title is-4" style="text-align: left;">Step 1: Latent Action Space Learning in Simulation</h3>
          <div class="content has-text-justified">
            <p>
              How can we learn a good latent action space that allows us to efficiently handle different downstream tasks?
              Unsupervised Skill Discovery (USD) provides an elegant solution, through maximizing the empowerment of the latent action space.
              However, USD often requires a large number of samples to converge, which is not practical to run on a real robot.
              <br>
              <br>
              But we do not necessarily have to run USD on a real robot!
              Instead, SLAC leverages a low-fidelity simulator for USD.
              Even if there is a reality gap, the learned latent action space can still be used to drive real-world policy learning as long as it has enough converage.
              Specifically, SLAC designs a novel USD objective that encourages temporally extended, disentangled, and safe latent actions, through the following pipeline:
            </p>
            <!-- <ul style="text-align: left;">
              <li>Learns temporally extended latent actions to reduce the exploration burden</li>
              <li>Enforces disentanglement between different latent dimensions to handle complex tasks</li>
              <li>Incorporates safety constraints to prevent dangerous behaviors</li>
            </ul> -->
            <!-- <p>
              These objectives are optimized through the following pipeline:
            </p> -->
          </div>
          <div class="publication-video" style="margin-top: -1rem; margin-bottom: 1rem;">
            <video
              src="static/videos/pipeline_1_low_res.mp4"
              style="width: 100%;aspect-ratio: 16/9;"
              class="no-loop"
              muted
              playsinline>
            </video>
          </div>

          <h3 class="title is-4" style="text-align: left;">Step 2: Real-World RL in the Learned Action Space</h3>
          <div class="content has-text-justified">
            <p>
              Once the latent action space is learned, SLAC trains a downstream policy in the learned action space.
              Specifically, we derive a novel off-policy RL algorithm on top of Soft Actor-Critic. Our algorithm not only handles discrete action space, 
              but can also leverage the dependencies between reward terms and latent action dimensions to decompose the RL training into parallel but easier sub-problems, thereby greatly reducing the sample complexity.
              We show the pipeline for downstream policy learning below:
            </p>
          </div>
          <div class="publication-video" style="margin-top: -1rem; margin-bottom: -1rem;">
            <video
              src="static/videos/website_videos2_low_res.mp4"
              style="width: 100%;aspect-ratio: 16/9;"
              class="no-loop"
              muted
              playsinline>
            </video>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">SLAC Real-World Training</h2>
          <p>
            In this video, we show one full training run for the board wiping task.
            The learned SLAC latent action space enables the robot to effectively explore the environment.
            Within 40 minutes of autonomous interactions, the robot learns
            to reliable wipe the whiteboard.
          </p>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/mmLUsGoK28Y" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="grid-container-one-no-box">
        <h2 class="title is-3 has-text-centered">Real-World Results</h2>
        <h2 class="title is-4">Policies Visualization</h2>
        <p>
          The SLAC framework does not require any demonstrations or hand-crafted behavior priors, and can be easily applied to a variety of tasks.
          We test SLAC on a suite of <strong>contact-rich, visuomotor</strong> bimanual mobile manipulation tasks, and show learned policies below.
        </p>
        <div class="grid-item">
          <div class="card-static-container">
            <div class="card-container">
              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/j7eYAJqAxaA"
                    width="100%"
                    height="280px"
                    class="no-autoplay"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Wipe a Whiteboard</strong></h3>
                  <p>SLAC policy continuously wipe a whiteboard by simultaneously moving its arms and base, while utilizing its active camera to keep track of the mark.</p>
                </div>
              </div>

              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/91dHyTkHH2g"
                    width="100%"
                    height="280px"
                    class="no-autoplay"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Wipe over Obstacle</strong></h3>
                  <p>SLAC policy learns to position its base such that it will not collide with the obstacle. In the meantime, it succecsfully wipes the mark on the whiteboard.</p>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="grid-item">
          <div class="card-static-container">
            <div class="card-container">
              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/azvZwjmmXTU"
                    width="100%"
                    height="280px"
                    class="no-autoplay"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Push to Tray</strong></h3>
                  <p>SLAC policy learns to use the broom in hand to push trash on the table into a tray.</p>
                </div>
              </div>

              <div class="card-wide">
                <div class="card-video">
                  <iframe
                    src="https://www.youtube.com/embed/18NYM-knLt8"
                    width="100%"
                    height="280px"
                    class="no-autoplay"
                    frameborder="0"
                    allow="autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen>
                  </iframe>
                </div>
                <div class="card-content">
                  <h3><strong>Sweep into Bag</strong></h3>
                  <p>SLAC learns to sweep trash off the table, while using a bag in the other hand to catch the trash.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

    </div>
  <!-- </section>

  <section class="section hero"> -->
    <div class="container is-max-desktop">
      <h2 class="title is-4" id="Simulation examples">Quantitative Results</h2>
      <div class="columns is-centered">
        <div class="column is-full-width is-centered has-text-centered">
          <div class="content has-text-justified">
            <p>
              Quantitatively, SLAC achieves significantly higher performance compared to state-of-the-art real-world RL and sim-to-real RL methods.
            </p>
          </div>
          <img src="static/images/success_plot.svg" width="70%"/>
          <div class="content has-text-justified">
            <p>
              More importantly, it stays safe during the entire training process, with minimal collisions nor excessive force!
            </p>
          </div>
          <img src="static/images/safety_plot.svg" width="70%"/>
        </div>
      </div>
    </div>
  <!-- </section>

  <section class="section hero"> -->
    <div class="container is-max-desktop">
      <div class="grid-container-one-no-box">
        <h2 class="title is-4">Additional Visualization</h2>
        <p>
          Finally, we show some additional visualization for our experiments, 
          including visualizations of the learned latent actions space, and visualizations of SLAC's performance on a non-robotics particle domain. 
        </p>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-two-fifths">
            <div class="card-mid">
              <div class="card-content">
                <div class="image-grid-part">
                  <video
                    src="static/images/table.mp4"
                    style="width: 100%;aspect-ratio: 4/3;"
                    muted
                    playsinline
                    loop>
                  </video>
                  <video
                    src="static/images/board.mp4"
                    style="width: 100%;aspect-ratio: 4/3;"
                    muted
                    playsinline
                    loop>
                  </video>
                </div>
                <h3><strong>Learned Latent Action Space</strong></h3>
                <p>Here, we visualize the learned latent action space by randomly sampling latent actions and visualizing the behavior in simulation.</p>
              </div>
            </div>
          </div>
          <div class="column is-two-fifths">
            <div class="card-mid">
              <div class="card-content">
                <div class="image-grid-part">
                  <img src="static/images/particle.gif" style="border: 2px solid black; width: 75%;">
                  <img src="static/images/particle.jpg" style="width: 100%;">
                </div>
                <h3><strong>Particle Domain</strong></h3>
                <p>SLAC can be applied to a variety of domains. Here we show the result of applying SLAC to a multi-agent domain.</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>
